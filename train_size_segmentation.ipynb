{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import copy\n",
    "import h5py\n",
    "import imgaug.augmenters as iaa\n",
    "import numpy as np\n",
    "from os import getcwd as cwd\n",
    "from os.path import join as pj\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import visdom\n",
    "\n",
    "# Logger\n",
    "from IO.logger import Logger\n",
    "# model\n",
    "from model.segnet.segnet import SegNet_\n",
    "from model.unet.unet import Unet_\n",
    "from model.optimizer import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    experiment_name = \"segnet_b20_lr1e-6_aug_pretrain\"\n",
    "    # paths\n",
    "    all_data_path = pj(cwd(), \"data/all_classification_data\", \"classify_insect_std_20200806_size_seg_step\")\n",
    "    model_root = pj(cwd(), \"output_model/size_segmentation\", experiment_name)\n",
    "    # train config\n",
    "    model_name = \"segnet\" # select in [\"segnet\", \"unet\"]\n",
    "    bs = 20\n",
    "    lr = 1e-6\n",
    "    nepoch = 100\n",
    "    plus_distance = False # use if loss = segmentation_loss + distance_loss\n",
    "    alpha = 1e-2 # use if plus_distance = True\n",
    "    pretrain = True\n",
    "    # visdom\n",
    "    visdom = True\n",
    "    port = 8097"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    args.cuda = True\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    args.cuda = False\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_logger = Logger(args)\n",
    "args_logger.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.visdom:\n",
    "    # Create visdom\n",
    "    vis = visdom.Visdom(port=args.port)\n",
    "    \n",
    "    win_train_loss = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='train_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    win_train_dist_diff = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='train_dist_diff',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    win_test_loss = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='test_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    win_test_dist_diff = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='test_dist_diff',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(vis, phase, visualized_data, window):\n",
    "    vis.line(\n",
    "        X=np.array([phase]),\n",
    "        Y=np.array([visualized_data]),\n",
    "        update='append',\n",
    "        win=window\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class size_segmentation_dataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, images, labels=None, training=False, evaluation=False):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.training = training\n",
    "        self.evaluation = evaluation\n",
    "        \n",
    "        aug_list = [\n",
    "            iaa.pillike.Autocontrast(),\n",
    "            iaa.Invert(0.5),\n",
    "            iaa.pillike.Equalize(),\n",
    "            iaa.Solarize(0.5, threshold=(32, 128)),\n",
    "            iaa.color.Posterize(),\n",
    "            iaa.pillike.EnhanceContrast(),\n",
    "            iaa.pillike.EnhanceColor(),\n",
    "            iaa.pillike.EnhanceBrightness(),\n",
    "            iaa.pillike.EnhanceSharpness(),\n",
    "        ]\n",
    "        self.aug_seq = iaa.SomeOf((0, 2), aug_list, random_order=True)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index].astype(\"uint8\")\n",
    "        if self.training is True:\n",
    "            image = self.aug_seq(image=image)\n",
    "        \n",
    "        image = image.astype(\"float32\")\n",
    "        image = cv2.normalize(image, image, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "        image = image.transpose(2,0,1).astype(\"float32\")\n",
    "        image = torch.from_numpy(image)\n",
    "        \n",
    "        if self.training is True or self.evaluation is True:\n",
    "            label = self.labels[index].astype(\"float32\")\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, test_dataloader, lr=1e-5, nepoch=100, visdom=False):\n",
    "    # define loss\n",
    "    l1_loss = nn.L1Loss(reduction='mean')\n",
    "    \n",
    "    # define optimizer\n",
    "    opt = AdamW(model.parameters(), lr=lr)\n",
    "    \n",
    "    # set model train mode\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(nepoch):\n",
    "        total_train_loss = 0\n",
    "        total_test_loss = 0\n",
    "        total_train_dist_diff = 0\n",
    "        total_test_dist_diff = 0\n",
    "        # train\n",
    "        count = 0\n",
    "        for image, label in train_dataloader:\n",
    "            count += 1\n",
    "            label = label[:, None, :, :]\n",
    "            if args.cuda is True:\n",
    "                image = image.cuda()\n",
    "                label = label.cuda()\n",
    "            opt.zero_grad()\n",
    "            out = model(image)\n",
    "            train_loss = l1_loss(out, label)\n",
    "            target_distances = calc_distance(label.squeeze(1))\n",
    "            output_distances = calc_distance(out.squeeze(1))\n",
    "            if args.cuda is True:\n",
    "                target_distances = target_distances.cuda()\n",
    "                output_distances = output_distances.cuda()\n",
    "            train_dist_diff = l1_loss(target_distances, output_distances)\n",
    "            if args.plus_distance is True:\n",
    "                train_loss += args.alpha * train_dist_diff\n",
    "            total_train_loss += train_loss.item()\n",
    "            total_train_dist_diff += train_dist_diff.item()\n",
    "            train_loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        print(\"train: target_dist = {}, output_dist = {}\".format(target_distances[0], output_distances[0]))\n",
    "        total_train_avg_dist_diff = total_train_dist_diff / count\n",
    "        \n",
    "        # valid\n",
    "        model.eval()\n",
    "        count = 0\n",
    "        for image, label in test_dataloader:\n",
    "            count += 1\n",
    "            label = label[:, None, :, :]\n",
    "            if args.cuda is True:\n",
    "                image = image.cuda()\n",
    "                label = label.cuda()\n",
    "            out = model(image)\n",
    "            test_loss = l1_loss(out, label)\n",
    "            target_distances = calc_distance(label.squeeze(1))\n",
    "            output_distances = calc_distance(out.squeeze(1))\n",
    "            if args.cuda is True:\n",
    "                target_distances = target_distances.cuda()\n",
    "                output_distances = output_distances.cuda()\n",
    "            test_dist_diff = l1_loss(target_distances, output_distances)\n",
    "            total_test_loss += test_loss.item()\n",
    "            total_test_dist_diff += test_dist_diff.item()\n",
    "            \n",
    "        print(\"test: target_dist = {}, output_dist = {}\".format(target_distances[0], output_distances[0]))\n",
    "        total_test_avg_dist_diff = total_test_dist_diff / count\n",
    "        model.train()\n",
    "        \n",
    "        if visdom:\n",
    "            visualize(vis, epoch+1, total_train_loss, win_train_loss)\n",
    "            visualize(vis, epoch+1, total_train_avg_dist_diff, win_train_dist_diff)\n",
    "            visualize(vis, epoch+1, total_test_loss, win_test_loss)\n",
    "            visualize(vis, epoch+1, total_test_avg_dist_diff, win_test_dist_diff)\n",
    "        print(\"epoch=%s: train_loss=%f, train_dist_diff=%f, test_loss=%f, test_dist_diff=%f\" % \n",
    "              (epoch, total_train_loss, total_train_avg_dist_diff, \n",
    "               total_test_loss, total_test_avg_dist_diff))\n",
    "        print(\"---------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unravel_index(index, shape):\n",
    "    out = []\n",
    "    for dim in reversed(shape):\n",
    "        out.append(int(index % dim))\n",
    "        index = index // dim\n",
    "    return tuple(reversed(out))\n",
    "\n",
    "    \n",
    "def calc_distance(label):\n",
    "    label = torch.clone(label)\n",
    "    distances = []\n",
    "    for elem_label in label:\n",
    "        p1 = np.array(unravel_index(torch.argmax(elem_label), elem_label.shape))\n",
    "        elem_label[p1] = 0.\n",
    "        p2 = np.array(unravel_index(torch.argmax(elem_label), elem_label.shape))\n",
    "        distances.append(np.linalg.norm(p1 - p2))\n",
    "    return torch.Tensor(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with h5py.File(args.all_data_path) as f:\n",
    "    images = f[\"X\"][:]\n",
    "    labels = f[\"Y\"][:]\n",
    "    \n",
    "# define kfold\n",
    "kf = KFold(n_splits=5)\n",
    "valid_count = 0\n",
    "\n",
    "# cross validation\n",
    "for train_index, test_index in kf.split(images):\n",
    "    print(\"\")\n",
    "    valid_count += 1\n",
    "    print(\"----- valid {} -----\".format(valid_count))\n",
    "    print(\"\")\n",
    "    # create validation data\n",
    "    image_train, image_test = images[train_index], images[test_index]\n",
    "    label_train, label_test = labels[train_index], labels[test_index]\n",
    "    # create dataloader\n",
    "    train_dataset = size_segmentation_dataset(image_train, label_train, training=True)\n",
    "    train_dataloader = data.DataLoader(train_dataset, args.bs, num_workers=0, shuffle=True)\n",
    "    test_dataset = size_segmentation_dataset(image_test, label_test, training=False, evaluation=True)\n",
    "    test_dataloader = data.DataLoader(test_dataset, 1, num_workers=0, shuffle=False)\n",
    "    \n",
    "    # create model\n",
    "    print(\"model = {}\".format(args.model_name))\n",
    "    if args.model_name == \"unet\":\n",
    "        model = Unet_(3, 1, pretrained=args.pretrain).cuda()\n",
    "    else:\n",
    "        model = SegNet_(3, 1, pretrained=args.pretrain).cuda()\n",
    "    \n",
    "    # training\n",
    "    train(model, train_dataloader, test_dataloader, lr=args.lr, nepoch=args.nepoch, visdom=args.visdom)\n",
    "    torch.save(model.state_dict(), pj(args.model_root, \"final.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_100",
   "language": "python",
   "name": "pytorch_100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
