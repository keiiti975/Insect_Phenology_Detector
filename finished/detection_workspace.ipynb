{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "from os.path import join as pj\n",
    "from PIL import Image\n",
    "import torch\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.asarray(Image.open(pj(\"/Users/user/Desktop/git/Insect_Phenology_Detector/data/train_refined_images\", \"20180614-1959\" + \".png\")))\n",
    "default_height, default_width, _ = image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_to_name = {\n",
    "    0: \"Insect\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pj(\"/Users/user/Desktop/git/Insect_Phenology_Detector/data/train_detection_data/refinedet_all\", \"20180614-1959\" + \".txt\")) as f:\n",
    "    target_lines = f.readlines()\n",
    "\n",
    "bbs_list = []\n",
    "for target_line in target_lines:\n",
    "    target_line = target_line.split(\"\\n\")[0]\n",
    "    target_list = target_line.split(\" \")\n",
    "    x1 = float(target_list[0]) * default_width\n",
    "    x2 = float(target_list[2]) * default_width\n",
    "    y1 = float(target_list[1]) * default_height\n",
    "    y2 = float(target_list[3]) * default_height\n",
    "    bbs_list.append(BoundingBox(x1 = x1, x2 = x2, y1 = y1, y2 = y2, label = lbl_to_name[int(target_list[4])]))\n",
    "\n",
    "bbs = BoundingBoxesOnImage(bbs_list, shape=image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_random(image, resize_size, crop_num, bbs=None):\n",
    "    \"\"\"\n",
    "        crop img, type == \"RANDOM\"\n",
    "        Args:\n",
    "            - img: np.array, shape == [1, height, width, channel]\n",
    "            - resize_size: int, resized size of image\n",
    "            - crop_num: (int, int), (height_crop_num, width_crop_num)\n",
    "            but in this function, use height_crop_num * width_crop_num as number of crop image\n",
    "            - bbs: imgaug BoundingBox\n",
    "    \"\"\"\n",
    "    height_after_crop = int(image.shape[0] / crop_num[0])\n",
    "    width_after_crop = int(image.shape[1] / crop_num[1])\n",
    "    \n",
    "    image_aug_list = []\n",
    "    bbs_aug_list = []\n",
    "    for i in range(crop_num[0] * crop_num[1]):\n",
    "        # set augmentations\n",
    "        aug_seq = iaa.Sequential([\n",
    "            iaa.CropToFixedSize(width=width_after_crop, height=height_after_crop, position=\"uniform\"),\n",
    "            iaa.Resize({\"width\": resize_size, \"height\": resize_size})\n",
    "        ])\n",
    "        # augment img and target\n",
    "        if bbs is not None:\n",
    "            image_aug, bbs_aug = aug_seq(image=image, bounding_boxes=bbs)\n",
    "            # check coord in img shape\n",
    "            bbs_aug_before_check = bbs_aug.bounding_boxes\n",
    "            bbs_aug_after_check = copy.copy(bbs_aug.bounding_boxes)\n",
    "            for bb in bbs_aug_before_check:\n",
    "                if bb.is_fully_within_image(image_aug.shape):\n",
    "                    pass\n",
    "                else:\n",
    "                    bbs_aug_after_check.remove(bb)\n",
    "            # append img and target\n",
    "            if len(bbs_aug_after_check) > 0:\n",
    "                image_aug_list.append(image_aug)\n",
    "                bbs_aug_list.append(bbs_aug_after_check)\n",
    "        else:\n",
    "            image_aug = aug_seq(image=image)\n",
    "    \n",
    "    return np.array(image_aug_list), bbs_aug_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_spread_all_over(image, resize_size, crop_num, bbs=None):\n",
    "    \"\"\"\n",
    "        crop img, type == \"SPREAD_ALL_OVER\"\n",
    "        Args:\n",
    "            - img: np.array, shape == [1, height, width, channel]\n",
    "            - resize_size: int, resized size of image\n",
    "            - crop_num: (int, int), (height_crop_num, width_crop_num)\n",
    "            - bbs: imgaug BoundingBox\n",
    "    \"\"\"\n",
    "    height_after_crop = int(image.shape[0] / crop_num[0])\n",
    "    width_after_crop = int(image.shape[1] / crop_num[1])\n",
    "    \n",
    "    height_mov_ratio_per_crop = 1.0 / (crop_num[0] - 1)\n",
    "    width_mov_ratio_per_crop = 1.0 / (crop_num[1] - 1)\n",
    "    \n",
    "    image_aug_list = []\n",
    "    bbs_aug_list = []\n",
    "    # create crop img\n",
    "    for i in range(crop_num[0]):\n",
    "        for j in range(crop_num[1]):\n",
    "            # set augmentations\n",
    "            aug_seq = iaa.Sequential([\n",
    "                iaa.CropToFixedSize(width=width_after_crop, height=height_after_crop, position=(width_mov_ratio_per_crop * j, height_mov_ratio_per_crop * i)),\n",
    "                iaa.Resize({\"width\": resize_size, \"height\": resize_size})\n",
    "            ])\n",
    "            # augment img and target\n",
    "            if bbs is not None:\n",
    "                image_aug, bbs_aug = aug_seq(image=image, bounding_boxes=bbs)\n",
    "                # check coord in img shape\n",
    "                bbs_aug_before_check = bbs_aug.bounding_boxes\n",
    "                bbs_aug_after_check = copy.copy(bbs_aug.bounding_boxes)\n",
    "                for bb in bbs_aug_before_check:\n",
    "                    if bb.is_fully_within_image(image_aug.shape):\n",
    "                        pass\n",
    "                    else:\n",
    "                        bbs_aug_after_check.remove(bb)\n",
    "                # append img and target\n",
    "                if len(bbs_aug_after_check) > 0:\n",
    "                    image_aug_list.append(image_aug)\n",
    "                    bbs_aug_list.append(bbs_aug_after_check)\n",
    "            else:\n",
    "                image_aug = aug_seq(image=image)\n",
    "    \n",
    "    return np.array(image_aug_list), bbs_aug_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_crop, bbs_crop_list = crop_spread_all_over(image, 512, (5, 5), bbs)\n",
    "image_crop, bbs_crop_list = crop_random(image, 512, (5, 5), bbs)\n",
    "bbs_crop = [BoundingBoxesOnImage(bbs_crop_list[idx], shape=image_crop[idx].shape) for idx in range(len(bbs_crop_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_crop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bbs_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "image_after = bbs_crop[idx].draw_on_image(image_crop[idx], size=2)\n",
    "plt.imshow(image_after)\n",
    "idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_aug = [\"HorizontalFlip\", \"VerticalFlip\", \"Rotate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adopt_augmentation(image_crop, bbs_crop, method_aug=None):\n",
    "    \"\"\"\n",
    "        adopt augmentation to image_crop, bbs_crop\n",
    "        Args:\n",
    "            - image_crop: np.array, shape == [crop_num, height, width, channels], cropped images\n",
    "            - bbs_crop: [BoundingBoxesOnImage, ...], imgaug bounding box\n",
    "            - method_aug: [str, ...], adopt augmentation list\n",
    "    \"\"\"\n",
    "    if method_aug is None:\n",
    "        return image_crop, bbs_crop\n",
    "    else:\n",
    "        aug_list = []\n",
    "        # create augmentation\n",
    "        for augmentation in method_aug:\n",
    "            if augmentation == \"HorizontalFlip\":\n",
    "                aug_list.append(iaa.Fliplr(0.5))\n",
    "            elif augmentation == \"VerticalFlip\":\n",
    "                aug_list.append(iaa.Flipud(0.5))\n",
    "            elif augmentation == \"Rotate\":\n",
    "                aug_list.append(iaa.Rotate((-45, 45)))\n",
    "            else:\n",
    "                print(\"not implemented!: insect_dataset_from_voc_style_txt.adopt_augmentation\")\n",
    "        \n",
    "        aug_seq = iaa.SomeOf(1, aug_list)\n",
    "        \n",
    "        image_crop_aug = []\n",
    "        bbs_crop_aug = []\n",
    "        # adopt augmentation\n",
    "        for im_crop, bb_crop in zip(image_crop, bbs_crop):\n",
    "            im_crop_aug, bb_crop_aug = aug_seq(image=im_crop, bounding_boxes=bb_crop)\n",
    "            # check coord in im_crop_aug shape\n",
    "            bb_crop_aug_before_check = bb_crop_aug.bounding_boxes\n",
    "            bb_crop_aug_after_check = copy.copy(bb_crop_aug.bounding_boxes)\n",
    "            for bb in bb_crop_aug_before_check:\n",
    "                if bb.is_fully_within_image(im_crop_aug.shape):\n",
    "                    pass\n",
    "                else:\n",
    "                    bb_crop_aug_after_check.remove(bb)\n",
    "            # append im_crop_aug and bb_crop_aug\n",
    "            if len(bb_crop_aug_after_check) > 0:\n",
    "                image_crop_aug.append(im_crop_aug)\n",
    "                bbs_crop_aug.append(bb_crop_aug_after_check)\n",
    "        \n",
    "        return np.array(image_crop_aug), bbs_crop_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_crop_aug, bbs_crop_aug_list = adopt_augmentation(image_crop, bbs_crop, method_aug)\n",
    "bbs_crop_aug = [BoundingBoxesOnImage(bbs_crop_aug_list[idx], shape=image_crop_aug[idx].shape) for idx in range(len(bbs_crop_aug_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_crop_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bbs_crop_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "image_after = bbs_crop_aug[idx].draw_on_image(image_crop_aug[idx], size=2)\n",
    "plt.imshow(image_after)\n",
    "idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_lbl = {\n",
    "    \"Insect\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pytorch_annotation(bbs_crop_aug, resize_size, name_to_lbl):\n",
    "    \"\"\"\n",
    "        extract bounding box and convert to pytorch style\n",
    "        Args:\n",
    "            - bbs_crop_aug: [BoundingBoxesOnImage, ...], imgaug bounding box\n",
    "    \"\"\"\n",
    "    target = []\n",
    "    for bb_crop_aug in bbs_crop_aug:\n",
    "        target_per_image = []\n",
    "        for elem_bb in bb_crop_aug:\n",
    "            x1 = elem_bb.x1 / float(resize_size)\n",
    "            y1 = elem_bb.y1 / float(resize_size)\n",
    "            x2 = elem_bb.x2 / float(resize_size)\n",
    "            y2 = elem_bb.y2 / float(resize_size)\n",
    "            lbl = int(name_to_lbl[elem_bb.label])\n",
    "            target_per_image.append([x1, y1, x2, y2, lbl])\n",
    "        target.append(torch.Tensor(target_per_image))\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = create_pytorch_annotation(bbs_crop_aug, 512, name_to_lbl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
