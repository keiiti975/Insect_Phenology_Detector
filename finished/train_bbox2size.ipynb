{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os import getcwd as cwd\n",
    "from os.path import join as pj\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import visdom\n",
    "\n",
    "# Logger\n",
    "from IO.logger import Logger\n",
    "# Data Sampling\n",
    "from dataset.classification.sampler import adopt_sampling\n",
    "# model\n",
    "from model.optimizer import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    experiment_name = \"linearNet_b80_l3_f100_oversample\"\n",
    "    # paths\n",
    "    bbox_data_path = pj(cwd(), \"data/bbox_data\", \"target_only_20200806.csv\")\n",
    "    figure_root = pj(cwd(), \"figure/bbox2size\", experiment_name)\n",
    "    model_root = pj(cwd(), \"output_model/bbox2size\", experiment_name)\n",
    "    # model config\n",
    "    linear_num = 3\n",
    "    feature_num = 100\n",
    "    # train config\n",
    "    bs = 80\n",
    "    lr = 1e-3\n",
    "    nepoch = 300\n",
    "    sampling = \"OverSample\" # choice [None, \"RandomSample\", \"OverSample\"]\n",
    "    use_WN_L1Loss = False\n",
    "    # visdom\n",
    "    visdom = False\n",
    "    port = 8097"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(args.figure_root) is False:\n",
    "    os.makedirs(args.figure_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    args.cuda = True\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    args.cuda = False\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "torch.multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_logger = Logger(args)\n",
    "args_logger.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.visdom:\n",
    "    # Create visdom\n",
    "    vis = visdom.Visdom(port=args.port)\n",
    "    \n",
    "    win_train_loss = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='train_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    win_test_loss = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='test_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(vis, phase, visualized_data, window):\n",
    "    vis.line(\n",
    "        X=np.array([phase]),\n",
    "        Y=np.array([visualized_data]),\n",
    "        update='append',\n",
    "        win=window\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bbox2size_dataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, bbox_data, size_data=None, mode=\"test\"):\n",
    "        self.bbox_data = bbox_data\n",
    "        self.size_data = size_data\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        bbox = self.bbox_data[index].astype(\"float32\")\n",
    "        bbox = torch.from_numpy(bbox)\n",
    "        \n",
    "        if self.mode == \"train\" or self.mode == \"eval\":\n",
    "            size = self.size_data[index].astype(\"float32\")\n",
    "            return bbox, size\n",
    "        else:\n",
    "            return bbox\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.bbox_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, linear_num=2, feature_num=100):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.linear_num = linear_num\n",
    "        self.feature_num = feature_num\n",
    "        \n",
    "        # define activation function\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # create model\n",
    "        layers = []\n",
    "        for i in range(linear_num):\n",
    "            if i == 0:\n",
    "                linear = nn.Linear(3, feature_num)\n",
    "                layers += [linear, self.relu]\n",
    "            elif i == linear_num - 1:\n",
    "                linear = nn.Linear(feature_num, 1)\n",
    "                layers += [linear]\n",
    "            else:\n",
    "                linear = nn.Linear(feature_num, feature_num)\n",
    "                layers += [linear, self.relu]\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weight_Normalized_L1loss(nn.L1Loss):\n",
    "    \n",
    "    def __init__(self, weight, reduction='mean'):\n",
    "        super(Weight_Normalized_L1loss, self).__init__(size_average=None, reduce=None, reduction=reduction)\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "        self.l1loss = nn.L1Loss(reduction='none')\n",
    "        \n",
    "    def forward(self, output_class, output, target):\n",
    "        weight = self.weight[output_class]\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(weight * self.l1loss(output, target))\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(weight * self.l1loss(output, target))\n",
    "        else:\n",
    "            print(\"error! Weight_Normalized_L1loss.forward\")\n",
    "\n",
    "            \n",
    "def define_weight(bbox_train):\n",
    "    labels = bbox_train[:, 2]\n",
    "    _, count = np.unique(labels, return_counts=True)\n",
    "    weight = 1 / (count/count.sum())\n",
    "    return torch.Tensor(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, test_dataloader, lr=1e-4, nepoch=100, visdom=False, use_WN_L1Loss=False):\n",
    "    # define loss\n",
    "    if use_WN_L1Loss is True:\n",
    "        train_l1_loss = Weight_Normalized_L1loss(define_weight(bbox_train))\n",
    "    else:\n",
    "        train_l1_loss = nn.L1Loss(reduction='mean')\n",
    "    test_l1_loss = nn.L1Loss(reduction='mean')\n",
    "    \n",
    "    # define optimizer\n",
    "    opt = AdamW(model.parameters(), lr=lr)\n",
    "    # set model train mode\n",
    "    model.train()\n",
    "    \n",
    "    # set best loss\n",
    "    best_total_test_avg_loss = 1e6\n",
    "    \n",
    "    for epoch in range(nepoch):\n",
    "        total_train_loss = 0\n",
    "        total_test_loss = 0\n",
    "        # train\n",
    "        count = 0\n",
    "        for bbox, size in train_dataloader:\n",
    "            count += 1\n",
    "            if args.cuda is True:\n",
    "                bbox = bbox.cuda()\n",
    "                size = size.cuda()\n",
    "            opt.zero_grad()\n",
    "            out = model(bbox)\n",
    "            if use_WN_L1Loss is True:\n",
    "                train_loss = train_l1_loss(bbox[:, 2].long(), out, size[:, None])\n",
    "            else:\n",
    "                train_loss = train_l1_loss(out, size[:, None])\n",
    "            total_train_loss += train_loss.item()\n",
    "            train_loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        total_train_avg_loss = total_train_loss / count\n",
    "        \n",
    "        # valid\n",
    "        model.eval()\n",
    "        count = 0\n",
    "        for bbox, size in test_dataloader:\n",
    "            count += 1\n",
    "            if args.cuda is True:\n",
    "                bbox = bbox.cuda()\n",
    "                size = size.cuda()\n",
    "            out = model(bbox)\n",
    "            test_loss = test_l1_loss(out, size[:, None])\n",
    "            total_test_loss += test_loss.item()\n",
    "            \n",
    "        total_test_avg_loss = total_test_loss / count\n",
    "        model.train()\n",
    "        \n",
    "        if total_test_avg_loss < best_total_test_avg_loss:\n",
    "            best_total_test_avg_loss = total_test_avg_loss\n",
    "            torch.save(model.state_dict(), pj(args.model_root, \"valid_\" + str(valid_count) + \"_best.pth\"))\n",
    "            with open(pj(args.model_root, \"valid_\" + str(valid_count) + \"_best_loss.txt\"), mode=\"w\") as f:\n",
    "                f.write(\"epoch = {}, test_loss = {}\".format(epoch, total_test_avg_loss))\n",
    "        \n",
    "        if visdom:\n",
    "            visualize(vis, epoch+1, total_train_avg_loss, win_train_loss)\n",
    "            visualize(vis, epoch+1, total_test_avg_loss, win_test_loss)\n",
    "        print(\"epoch=%s: train_loss=%f, test_loss=%f\" % (epoch, total_train_avg_loss, total_test_avg_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_size(model, all_dataloader):\n",
    "    size_array = []\n",
    "    \n",
    "    model.eval()\n",
    "    for bbox, _ in all_dataloader:\n",
    "        if args.cuda is True:\n",
    "            bbox = bbox.cuda()\n",
    "        out = model(bbox)\n",
    "        size_array.extend(out[:, 0].cpu().detach().numpy())\n",
    "\n",
    "    model.train()\n",
    "    return size_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "bbox_df = pd.read_csv(args.bbox_data_path)\n",
    "bbox_data = np.array(bbox_df.loc[:, [\"width\", \"height\", \"label\"]])\n",
    "size_data = np.array(bbox_df.loc[:, \"size\"])\n",
    "label_data = np.array(bbox_df.loc[:, \"label\"])\n",
    "all_dataset = bbox2size_dataset(bbox_data, size_data, mode=\"eval\")\n",
    "all_dataloader = data.DataLoader(all_dataset, 1, num_workers=0, shuffle=False)\n",
    "\n",
    "# define kfold\n",
    "kf = KFold(n_splits=5)\n",
    "valid_count = 0\n",
    "\n",
    "# cross validation\n",
    "total_eval_train_loss = 0\n",
    "total_eval_test_loss = 0\n",
    "total_eval_all_loss = 0\n",
    "for train_index, test_index in kf.split(bbox_data):\n",
    "    print(\"\")\n",
    "    valid_count += 1\n",
    "    print(\"----- valid {} -----\".format(valid_count))\n",
    "    print(\"\")\n",
    "    # create validation data\n",
    "    train_index = adopt_sampling(label_data, train_index, args.sampling)\n",
    "    bbox_train, bbox_test = bbox_data[train_index], bbox_data[test_index]\n",
    "    size_train, size_test = size_data[train_index], size_data[test_index]\n",
    "    # create dataloader\n",
    "    train_dataset = bbox2size_dataset(bbox_train, size_train, mode=\"train\")\n",
    "    train_dataloader = data.DataLoader(train_dataset, args.bs, num_workers=0, shuffle=True)\n",
    "    valid_dataset = bbox2size_dataset(bbox_train, size_train, mode=\"eval\")\n",
    "    valid_dataloader = data.DataLoader(valid_dataset, 1, num_workers=0, shuffle=False)\n",
    "    test_dataset = bbox2size_dataset(bbox_test, size_test, mode=\"eval\")\n",
    "    test_dataloader = data.DataLoader(test_dataset, 1, num_workers=0, shuffle=False)\n",
    "    \n",
    "    # create model\n",
    "    model = LinearNet(linear_num=args.linear_num, feature_num=args.feature_num).cuda()\n",
    "    \n",
    "    # training\n",
    "    train(model, train_dataloader, test_dataloader, lr=args.lr, nepoch=args.nepoch, visdom=args.visdom, use_WN_L1Loss=args.use_WN_L1Loss)\n",
    "    \n",
    "    # evaluation\n",
    "    model.load_state_dict(torch.load(pj(args.model_root, \"valid_\" + str(valid_count) + \"_best.pth\")))\n",
    "    \n",
    "    estimated_size_array = estimate_size(model, valid_dataloader)\n",
    "    eval_train_loss = np.sum(np.abs(estimated_size_array - size_train)) / len(size_train)\n",
    "    total_eval_train_loss += eval_train_loss\n",
    "    \n",
    "    estimated_size_array = estimate_size(model, test_dataloader)\n",
    "    eval_test_loss = np.sum(np.abs(estimated_size_array - size_test)) / len(size_test)\n",
    "    total_eval_test_loss += eval_test_loss\n",
    "    \n",
    "    estimated_size_array = estimate_size(model, all_dataloader)\n",
    "    eval_all_loss = np.sum(np.abs(estimated_size_array - size_data)) / len(size_data)\n",
    "    total_eval_all_loss += eval_all_loss\n",
    "    \n",
    "    valid_loss = pd.DataFrame({\"train\": [eval_train_loss], \"test\": [eval_test_loss], \"all\": [eval_all_loss]})\n",
    "    valid_loss.to_csv(pj(args.figure_root, \"valid_loss_\" + str(valid_count) + \".csv\"))\n",
    "    \n",
    "    bbox_df_with_estimate_size = pd.DataFrame({\"size\": size_data})\n",
    "    bbox_df_with_estimate_size[\"eval_size\"] = estimated_size_array\n",
    "    bbox_df_with_estimate_size.to_csv(pj(args.figure_root, \"output_size_\" + str(valid_count) + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss = pd.DataFrame({\"train\": [total_eval_train_loss / 5], \"test\": [total_eval_test_loss / 5], \"all\": [total_eval_all_loss / 5]})\n",
    "valid_loss.to_csv(pj(args.figure_root, \"final_loss_\" + str(valid_count) + \".csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_100",
   "language": "python",
   "name": "pytorch_100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
