{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from numpy.random import *\n",
    "from os import listdir as ld\n",
    "from os.path import join as pj\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import visdom\n",
    "\n",
    "# Logger\n",
    "from IO.logger import Logger\n",
    "# Loader\n",
    "from IO.loader import load_path, load_images, load_annotations_path, load_annotations, get_anno_recs\n",
    "# Dataset\n",
    "from dataset.detection.dataset import insects_dataset_from_voc_style_txt, collate_fn\n",
    "# Loss Function\n",
    "from model.refinedet.loss.multiboxloss import RefineDetMultiBoxLoss\n",
    "# Model initializer\n",
    "from model.refinedet.utils.initializer import initialize_model\n",
    "# Predict\n",
    "from model.refinedet.utils.predict import test_prediction\n",
    "# Evaluate\n",
    "from evaluation.detection.evaluate import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    # experiment name\n",
    "    experiment_name = \"crop_b2_2_4_8_16_32_im512_CSL_param2\"\n",
    "    # paths\n",
    "    data_root = \"/home/tanida/workspace/Insect_Phenology_Detector/data\"\n",
    "    train_image_root = \"/home/tanida/workspace/Insect_Phenology_Detector/data/train_refined_images\"\n",
    "    train_target_root = \"/home/tanida/workspace/Insect_Phenology_Detector/data/train_detection_data/refinedet_all\"\n",
    "    test_image_root = \"/home/tanida/workspace/Insect_Phenology_Detector/data/test_refined_images\"\n",
    "    basenet = \"/home/tanida/workspace/Insect_Phenology_Detector/output_model/detection/RefineDet/weights/vgg16_reducedfc.pth\"\n",
    "    model_root = pj(\"/home/tanida/workspace/Insect_Phenology_Detector/output_model/detection/RefineDet\", experiment_name)\n",
    "    test_anno_folders = [\"annotations_4\"]\n",
    "    # training config\n",
    "    input_size = 512 # choices=[320, 512, 1024]\n",
    "    crop_num = (5, 5)\n",
    "    batch_size = 2\n",
    "    num_workers = 2\n",
    "    lr = 1e-4\n",
    "    lamda = 1e-4\n",
    "    tcb_layer_num = 5\n",
    "    rm_last = True\n",
    "    max_epoch = 100\n",
    "    valid_interval = 2\n",
    "    save_interval = 20\n",
    "    pretrain = False\n",
    "    use_CSL = True\n",
    "    CSL_weight = [0.8, 1.2]\n",
    "    # visualization\n",
    "    visdom = True\n",
    "    visdom_port = 8097"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.tcb_layer_num == 4 and args.rm_last == False:\n",
    "    from model.refinedet.config import tcb_4_rm_false as insect_refinedet\n",
    "elif args.tcb_layer_num == 4 and args.rm_last == True:\n",
    "    from model.refinedet.config import tcb_4_rm_true as insect_refinedet\n",
    "elif args.tcb_layer_num == 5 and args.rm_last == False:\n",
    "    from model.refinedet.config import tcb_5_rm_false as insect_refinedet\n",
    "elif args.tcb_layer_num == 5 and args.rm_last == True:\n",
    "    from model.refinedet.config import tcb_5_rm_true as insect_refinedet\n",
    "elif args.tcb_layer_num == 6 and args.rm_last == False:\n",
    "    from model.refinedet.config import tcb_6_rm_false as insect_refinedet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.visdom:\n",
    "    # Create visdom\n",
    "    vis = visdom.Visdom(port=args.visdom_port)\n",
    "    \n",
    "    \"\"\"train_lossl\"\"\"\n",
    "    win_arm_loc = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='arm_loc_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    win_arm_conf = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='arm_conf_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    win_odm_loc = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='odm_loc_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    win_odm_conf = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='odm_conf_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    win_norm_loss = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='normalization_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    win_all_loss = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='train_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    win_valid_acc = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='validation_accuracy',\n",
    "            xlabel='epoch',\n",
    "            ylabel='average precision',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(phase, visualized_data, window):\n",
    "    vis.line(\n",
    "        X=np.array([phase]),\n",
    "        Y=np.array([visualized_data]),\n",
    "        update='append',\n",
    "        win=window\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.rm_last == True:\n",
    "    from model.refinedet.refinedet_rmlast import build_refinedet\n",
    "else:\n",
    "    from model.refinedet.refinedet import build_refinedet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_criterion = RefineDetMultiBoxLoss(2, 0.5, True, 0, True, 3, 0.5,\n",
    "                         False, True, use_CSL=args.use_CSL, CSL_weight=args.CSL_weight)\n",
    "odm_criterion = RefineDetMultiBoxLoss(2, 0.5, True, 0, True, 3, 0.5,\n",
    "                         False, True, use_ARM=True, use_CSL=args.use_CSL, CSL_weight=args.CSL_weight)\n",
    "l2_loss = nn.MSELoss(reduction='elementwise_mean').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_per_epoch(model, data_loader, optimizer, epoch):\n",
    "    # set refinedet to train mode\n",
    "    model.train()\n",
    "    model.phase = \"train\"\n",
    "\n",
    "    # create loss counters\n",
    "    arm_loc_loss = 0\n",
    "    arm_conf_loss = 0\n",
    "    odm_loc_loss = 0\n",
    "    odm_conf_loss = 0\n",
    "    all_norm_loss = 0\n",
    "\n",
    "    # train\n",
    "    for images, targets, _, _, _ in tqdm(data_loader, leave=False):\n",
    "        imgs = np.asarray(images[0])\n",
    "        tars = targets[0]\n",
    "\n",
    "        refined_imgs = []\n",
    "        refined_tars = []\n",
    "        # refine imgs, tars\n",
    "        for i in range(imgs.shape[0]):\n",
    "            if tars[i].size(0) > 0:\n",
    "                refined_imgs.append(imgs[i])\n",
    "                refined_tars.append(tars[i])\n",
    "        imgs = np.asarray(refined_imgs)\n",
    "        tars = refined_tars\n",
    "\n",
    "        # define batch_num\n",
    "        if (imgs.shape[0]%args.batch_size == 0):\n",
    "            batch_num = int(imgs.shape[0]/args.batch_size)\n",
    "        else:\n",
    "            batch_num = int(imgs.shape[0]/args.batch_size) + 1\n",
    "\n",
    "        # random sample of batch\n",
    "        iter_batch = choice(range(batch_num), batch_num, replace=False)\n",
    "\n",
    "        # train for cropped image\n",
    "        for i in iter_batch:\n",
    "            images = imgs[i*args.batch_size:(i+1)*args.batch_size]\n",
    "            targets = tars[i*args.batch_size:(i+1)*args.batch_size]\n",
    "\n",
    "            # set cuda\n",
    "            images = torch.from_numpy(images).cuda()\n",
    "            targets = [ann.cuda() for ann in targets]\n",
    "\n",
    "            # forward\n",
    "            out = model(images)\n",
    "\n",
    "            # calculate loss\n",
    "            optimizer.zero_grad()\n",
    "            arm_loss_l, arm_loss_c = arm_criterion(out, targets)\n",
    "            odm_loss_l, odm_loss_c = odm_criterion(out, targets)\n",
    "            arm_loss = arm_loss_l + arm_loss_c\n",
    "            odm_loss = odm_loss_l + odm_loss_c\n",
    "            loss = arm_loss + odm_loss\n",
    "\n",
    "            if args.lamda != 0:\n",
    "                norm_loss = 0\n",
    "                for param in model.parameters():\n",
    "                    param_target = torch.zeros(param.size()).cuda()\n",
    "                    norm_loss += l2_loss(param, param_target)\n",
    "\n",
    "                norm_loss = norm_loss * args.lamda\n",
    "                loss += norm_loss\n",
    "            else:\n",
    "                norm_loss = 0\n",
    "\n",
    "            if torch.isnan(loss) == 0:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                arm_loc_loss += arm_loss_l.item()\n",
    "                arm_conf_loss += arm_loss_c.item()\n",
    "                odm_loc_loss += odm_loss_l.item()\n",
    "                odm_conf_loss += odm_loss_c.item()\n",
    "                all_norm_loss += norm_loss.item()\n",
    "\n",
    "    print('epoch ' + str(epoch) + ' || ARM_L Loss: %.4f ARM_C Loss: %.4f ODM_L Loss: %.4f ODM_C Loss: %.4f NORM Loss: %.4f ||' \\\n",
    "    % (arm_loc_loss, arm_conf_loss, odm_loc_loss, odm_conf_loss, all_norm_loss))\n",
    "\n",
    "    # visualize\n",
    "    if args.visdom:\n",
    "        visualize(epoch+1, arm_loc_loss, win_arm_loc)\n",
    "        visualize(epoch+1, arm_conf_loss, win_arm_conf)\n",
    "        visualize(epoch+1, odm_loc_loss, win_odm_loc)\n",
    "        visualize(epoch+1, odm_conf_loss, win_odm_conf)\n",
    "        visualize(epoch+1, all_norm_loss, win_norm_loss)\n",
    "        visualize(epoch+1, arm_loc_loss + arm_conf_loss + odm_loc_loss + odm_conf_loss + all_norm_loss, win_all_loss)\n",
    "\n",
    "        \n",
    "def validate(model, data_loader, recs, crop_num, nms_thresh=0.3):\n",
    "    # set Faster_RCNN to eval mode\n",
    "    model.eval()\n",
    "    # predict and evaluate\n",
    "    result = test_prediction(model, data_loader, crop_num, nms_thresh=nms_thresh)\n",
    "    recall, precision, avg_precision, gt_dict = evaluate(result, recs, ovthresh=0.3)\n",
    "    \n",
    "    return avg_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_logger = Logger(args)\n",
    "args_logger.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = insect_refinedet[str(args.input_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading dataset for train ...')\n",
    "train_dataset = insects_dataset_from_voc_style_txt(args.train_image_root, args.input_size, args.crop_num, \"RefineDet\", training=True, target_root=args.train_target_root)\n",
    "train_data_loader = data.DataLoader(train_dataset, 1, num_workers=1, shuffle=True, collate_fn=collate_fn)\n",
    "print('Loading dataset for test ...')\n",
    "test_dataset = insects_dataset_from_voc_style_txt(args.test_image_root, args.input_size, args.crop_num, \"RefineDet\", training=False)\n",
    "test_data_loader = data.DataLoader(test_dataset, 1, num_workers=1, shuffle=False, collate_fn=collate_fn)\n",
    "print('Loading annotation for test...')\n",
    "test_annos, test_imgs = load_path(args.data_root, \"refined_images\", args.test_anno_folders)\n",
    "test_images = load_images(test_imgs)\n",
    "test_annotations_path = load_annotations_path(test_annos, test_images)\n",
    "test_anno = load_annotations(test_annotations_path)\n",
    "test_imagenames, test_recs = get_anno_recs(test_anno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_refinedet('train', insect_refinedet, args.input_size, args.tcb_layer_num).cuda()\n",
    "initialize_model(model, args.basenet, pretrain=args.pretrain)\n",
    "print(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(args.max_epoch):\n",
    "    train_per_epoch(model, train_data_loader, optimizer, epoch)\n",
    "    \n",
    "    # validate model\n",
    "    if epoch != 0 and epoch % args.valid_interval == 0:\n",
    "        average_precision = validate(model, test_data_loader, test_recs, args.crop_num)\n",
    "        print(\"epoch: {}, ap={}\".format(epoch, average_precision))\n",
    "        if args.visdom:\n",
    "            visualize(epoch + 1, average_precision, win_valid_acc)\n",
    "    \n",
    "    # save model\n",
    "    if epoch != 0 and epoch % args.save_interval == 0:\n",
    "        print('Saving state, epoch: ' + str(epoch))\n",
    "        torch.save(model.state_dict(), args.model_root + '/RefineDet{}_{}.pth'.format(args.input_size, str(epoch)))\n",
    "\n",
    "# final save model\n",
    "print('Saving state, final')\n",
    "torch.save(model.state_dict(), args.model_root + '/RefineDet{}_final.pth'.format(args.input_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_040",
   "language": "python",
   "name": "pytorch_040"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
