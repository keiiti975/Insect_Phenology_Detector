{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートブックの役割\n",
    "- 検出モデルの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- ライブラリ ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import *\n",
    "from os.path import join as pj\n",
    "from os import getcwd as cwd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import visdom\n",
    "\n",
    "# IO関連\n",
    "from IO.logger import Logger\n",
    "from IO.visdom import visualize\n",
    "# 検出データセット\n",
    "from dataset.detection.dataset import insects_dataset_from_voc_style_txt, collate_fn\n",
    "# モデル\n",
    "from model.refinedet.refinedet import RefineDet\n",
    "from model.refinedet.loss.multiboxloss import RefineDetMultiBoxLoss\n",
    "from model.refinedet.utils.predict import test_prediction\n",
    "from model.optimizer import AdamW, RAdam\n",
    "# 評価関数\n",
    "from evaluation.detection.evaluate import Voc_Evaluater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- 学習コンフィグ ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    # 実験名\n",
    "    experiment_name: str = \"\"\n",
    "    # パス\n",
    "    data_root: str = pj(cwd(), \"\")\n",
    "    train_image_root: str = pj(cwd(), \"\")\n",
    "    train_target_root: str = pj(cwd(), \"\")\n",
    "    test_image_root: str = pj(cwd(), \"\")\n",
    "    test_target_root: str = pj(cwd(), \"\")\n",
    "    model_root: str = pj(cwd(), \"\", experiment_name)\n",
    "    prc_root: str = pj(cwd(), \"\", experiment_name)\n",
    "    # 学習時の設定\n",
    "    input_size: int = 512 # [320, 512, 1024]から一つ選択\n",
    "    crop_num = (5, 5) # (w: int, h: int)\n",
    "    batch_size: int = 2\n",
    "    lr: float = 1e-4\n",
    "    lamda: float = 1e-4\n",
    "    tcb_layer_num: int = 6\n",
    "    use_extra_layer: bool = True\n",
    "    max_epoch: int = 100\n",
    "    valid_interval: int = 5\n",
    "    save_interval: int = 20\n",
    "    pretrain: bool = True\n",
    "    freeze: bool = True\n",
    "    optimizer: str = \"AdamW\" # [\"Adam, AdamW\", \"RAdam\"]から一つ選択\n",
    "    activation_function: str = \"ReLU\" # [\"ReLU\", \"LeakyReLU\", \"RReLU\"]から一つ選択, 他にも色々使える\n",
    "    init_function: str = \"xavier_uniform_\" # [\"xavier_uniform_\", \"xavier_normal_\", \"kaiming_uniform_\", \"kaiming_normal_\"]から一つ選択, 他にも色々使える\n",
    "    method_aug = [\"All\"] # dataset.classification.dataset.create_aug_seqにあるものから選択(複数可)\n",
    "    size_normalization: bool = False\n",
    "    augment_target: bool = False\n",
    "    use_GN_WS: bool = False\n",
    "    # Visdom\n",
    "    visdom: bool = False\n",
    "    visdom_port: int = 8097\n",
    "    # モデルタイプ\n",
    "    model_detect_type: str = \"all\" # [\"all\", \"each\", \"det2cls\"]から一つ選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model_detect_type == \"all\":\n",
    "    args.class_num = 2\n",
    "elif args.model_detect_type == \"each\":\n",
    "    args.class_num = 13\n",
    "elif args.model_detect_type == \"det2cls\":\n",
    "    args.class_num = 3\n",
    "else:\n",
    "    print(\"error! choice from all, each, det2cls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- CUDA関連 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "torch.multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- Visdom ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.visdom:\n",
    "    # Visdomを起動\n",
    "    vis = visdom.Visdom(port=args.visdom_port)\n",
    "    \n",
    "    \"\"\"ARM Loss\"\"\"\n",
    "    win_arm_loc = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='arm_loc_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    win_arm_conf = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='arm_conf_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    \"\"\"ODM Loss\"\"\"\n",
    "    win_odm_loc = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='odm_loc_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    win_odm_conf = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='odm_conf_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    \"\"\"Norm Loss\"\"\"\n",
    "    win_norm_loss = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='normalization_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    \"\"\"全体 Loss\"\"\"\n",
    "    win_all_loss = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='train_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    if args.model_detect_type == \"all\":\n",
    "        \"\"\"識別率\"\"\"\n",
    "        win_train_acc = vis.line(\n",
    "            X=np.array([0]),\n",
    "            Y=np.array([0]),\n",
    "            opts=dict(\n",
    "                title='train_accuracy',\n",
    "                xlabel='epoch',\n",
    "                ylabel='average precision',\n",
    "                width=800,\n",
    "                height=400\n",
    "            )\n",
    "        )\n",
    "        win_test_acc = vis.line(\n",
    "            X=np.array([0]),\n",
    "            Y=np.array([0]),\n",
    "            opts=dict(\n",
    "                title='test_accuracy',\n",
    "                xlabel='epoch',\n",
    "                ylabel='average precision',\n",
    "                width=800,\n",
    "                height=400\n",
    "            )\n",
    "        )\n",
    "    elif args.model_detect_type == \"det2cls\":\n",
    "        \"\"\"識別率\"\"\"\n",
    "        win_train_aquatic_acc = vis.line(\n",
    "            X=np.array([0]),\n",
    "            Y=np.array([0]),\n",
    "            opts=dict(\n",
    "                title='train_aquatic_accuracy',\n",
    "                xlabel='epoch',\n",
    "                ylabel='average precision',\n",
    "                width=800,\n",
    "                height=400\n",
    "            )\n",
    "        )\n",
    "        win_train_other_acc = vis.line(\n",
    "            X=np.array([0]),\n",
    "            Y=np.array([0]),\n",
    "            opts=dict(\n",
    "                title='train_other_accuracy',\n",
    "                xlabel='epoch',\n",
    "                ylabel='average precision',\n",
    "                width=800,\n",
    "                height=400\n",
    "            )\n",
    "        )\n",
    "        win_test_aquatic_acc = vis.line(\n",
    "            X=np.array([0]),\n",
    "            Y=np.array([0]),\n",
    "            opts=dict(\n",
    "                title='test_aquatic_accuracy',\n",
    "                xlabel='epoch',\n",
    "                ylabel='average precision',\n",
    "                width=800,\n",
    "                height=400\n",
    "            )\n",
    "        )\n",
    "        win_test_other_acc = vis.line(\n",
    "            X=np.array([0]),\n",
    "            Y=np.array([0]),\n",
    "            opts=dict(\n",
    "                title='test_other_accuracy',\n",
    "                xlabel='epoch',\n",
    "                ylabel='average precision',\n",
    "                width=800,\n",
    "                height=400\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- 学習関連 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_per_epoch(epoch, train_dataloader, opt, model, arm_loss, odm_loss, l2_loss, batch_size, lamda=0., visdom=False):\n",
    "    \"\"\"\n",
    "        1epochの学習コード\n",
    "        引数:\n",
    "            - epoch: int, 現在のエポック, 可視化に用いる\n",
    "            - train_dataloader: データローダ\n",
    "            - opt: 最適化器\n",
    "            - model: モデル\n",
    "            - arm_loss: ARMの誤差関数\n",
    "            - odm_loss: ODMの誤差関数\n",
    "            - l2_loss: L2誤差\n",
    "            - batch_size: int, 学習時のバッチサイズ\n",
    "            - lamda: float, モデル重み正規化での重み\n",
    "            - visdom: bool, visdomで可視化するかどうか\n",
    "    \"\"\"\n",
    "    # set model train mode\n",
    "    model.train()\n",
    "\n",
    "    # create loss counters\n",
    "    arm_loc_loss = 0\n",
    "    arm_conf_loss = 0\n",
    "    odm_loc_loss = 0\n",
    "    odm_conf_loss = 0\n",
    "    all_norm_loss = 0\n",
    "\n",
    "    # training\n",
    "    for images, targets, _, _, _ in tqdm(train_dataloader, leave=False):\n",
    "        imgs = np.array(images[0])\n",
    "        tars = targets[0]\n",
    "\n",
    "        # define batch_num\n",
    "        if (imgs.shape[0] % batch_size == 0):\n",
    "            batch_num = int(imgs.shape[0] / batch_size)\n",
    "        else:\n",
    "            batch_num = int(imgs.shape[0] / batch_size) + 1\n",
    "\n",
    "        # random sample of batch\n",
    "        iter_batch = choice(range(batch_num), batch_num, replace=False)\n",
    "\n",
    "        # train for cropped image\n",
    "        for i in iter_batch:\n",
    "            images = imgs[i * batch_size:(i+1) * batch_size]\n",
    "            targets = tars[i * batch_size:(i+1) * batch_size]\n",
    "\n",
    "            # set cuda\n",
    "            images = torch.from_numpy(images).cuda()\n",
    "            targets = [ann.cuda() for ann in targets]\n",
    "\n",
    "            # forward\n",
    "            out = model(images)\n",
    "\n",
    "            # calculate loss\n",
    "            opt.zero_grad()\n",
    "            arm_loss_l, arm_loss_c = arm_loss(out, targets)\n",
    "            odm_loss_l, odm_loss_c = odm_loss(out, targets)\n",
    "            arm_loss = arm_loss_l + arm_loss_c\n",
    "            odm_loss = odm_loss_l + odm_loss_c\n",
    "            loss = arm_loss + odm_loss\n",
    "\n",
    "            if lamda != 0:\n",
    "                norm_loss = 0\n",
    "                for param in model.parameters():\n",
    "                    param_target = torch.zeros(param.size()).cuda()\n",
    "                    norm_loss += l2_loss(param, param_target)\n",
    "\n",
    "                norm_loss = norm_loss * lamda\n",
    "                loss += norm_loss\n",
    "            else:\n",
    "                norm_loss = 0\n",
    "\n",
    "            if torch.isnan(loss) == 0:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                arm_loc_loss += arm_loss_l.item()\n",
    "                arm_conf_loss += arm_loss_c.item()\n",
    "                odm_loc_loss += odm_loss_l.item()\n",
    "                odm_conf_loss += odm_loss_c.item()\n",
    "                all_norm_loss += norm_loss.item()\n",
    "\n",
    "    print('epoch ' + str(epoch) + ' || ARM_L Loss: %.4f ARM_C Loss: %.4f ODM_L Loss: %.4f ODM_C Loss: %.4f NORM Loss: %.4f ||' \\\n",
    "    % (arm_loc_loss, arm_conf_loss, odm_loc_loss, odm_conf_loss, all_norm_loss))\n",
    "\n",
    "    # visualize\n",
    "    if visdom:\n",
    "        visualize(vis, epoch+1, arm_loc_loss, win_arm_loc)\n",
    "        visualize(vis, epoch+1, arm_conf_loss, win_arm_conf)\n",
    "        visualize(vis, epoch+1, odm_loc_loss, win_odm_loc)\n",
    "        visualize(vis, epoch+1, odm_conf_loss, win_odm_conf)\n",
    "        visualize(vis, epoch+1, all_norm_loss, win_norm_loss)\n",
    "        visualize(vis, epoch+1, arm_loc_loss + arm_conf_loss + odm_loc_loss + odm_conf_loss + all_norm_loss, win_all_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- 評価関連 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(evaluater, dataloader, model, crop_num, num_classes=2, nms_thresh=0.5):\n",
    "    \"\"\"\n",
    "        モデルのVOC-APを計算する\n",
    "        引数:\n",
    "            - evaluater: Voc_Evaluater, VOC-APを計算するクラス\n",
    "            - dataloader: データローダ\n",
    "            - model: モデル\n",
    "            - crop_num: (int, int), (縦のクロップ数, 横のクロップ数)\n",
    "            - num_classes: int, 分類するクラス数(前景+背景)\n",
    "            - nms_thresh: Non Maximum Suppressionを適用するconfidenceの閾値\n",
    "    \"\"\"\n",
    "    result = test_prediction(model, dataloader, crop_num, num_classes, nms_thresh)\n",
    "    evaluater.set_result(result)\n",
    "    eval_metrics = evaluater.get_eval_metrics()\n",
    "    return eval_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- コンフィグの保存 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_logger = Logger(args)\n",
    "args_logger.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- データ作成 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading dataset for train ...')\n",
    "train_dataset = insects_dataset_from_voc_style_txt(args.train_image_root, args.input_size, args.crop_num, training=True, \n",
    "                                                   target_root=args.train_target_root, method_crop=\"SPREAD_ALL_OVER\", \n",
    "                                                   method_aug=args.method_aug, model_detect_type=args.model_detect_type, \n",
    "                                                   size_normalization=args.size_normalization, augment_target=args.augment_target)\n",
    "train_dataloader = data.DataLoader(train_dataset, 1, num_workers=0, shuffle=True, collate_fn=collate_fn)\n",
    "print('Loading dataset for test ...')\n",
    "test_dataset = insects_dataset_from_voc_style_txt(args.test_image_root, args.input_size, args.crop_num, training=False)\n",
    "test_dataloader = data.DataLoader(test_dataset, 1, num_workers=0, shuffle=False, collate_fn=collate_fn)\n",
    "train_valid_dataset = insects_dataset_from_voc_style_txt(args.train_image_root, args.input_size, args.crop_num, training=False)\n",
    "train_valid_dataloader = data.DataLoader(train_valid_dataset, 1, num_workers=0, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- モデル作成 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RefineDet(args.input_size, args.class_num, args.tcb_layer_num, pretrain=args.pretrain, freeze=args.freeze, activation_function=args.activation_function, init_function=args.init_function, use_extra_layer=args.use_extra_layer, use_GN_WS=args.use_GN_WS)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- 最適化器作成 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.optimizer == \"Adam\":\n",
    "    print(\"optimizer == Adam\")\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "elif args.optimizer == \"AdamW\":\n",
    "    print(\"optimizer == AdamW\")\n",
    "    opt = AdamW(model.parameters(), lr=args.lr)\n",
    "elif args.optimizer == \"RAdam\":\n",
    "    print(\"optimizer == RAdam\")\n",
    "    opt = RAdam(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- 誤差定義 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_loss = RefineDetMultiBoxLoss(2, use_ARM=False) # ARMの誤差, クラス数は2で固定\n",
    "odm_loss = RefineDetMultiBoxLoss(args.class_num, use_ARM=True) # ODMの誤差, クラス数は背景+前景クラス\n",
    "l2_loss = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- メイン処理 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_disp_ap(test_ap, best_test_ap, model, model_root, epoch):\n",
    "    \"\"\"\n",
    "        最良モデルと, その時のAPを保存する\n",
    "        引数:\n",
    "            - test_ap: float, 現在のAP\n",
    "            - best_test_ap: float, 最良のAP\n",
    "            - model: モデル\n",
    "            - model_root: str, モデルを保存する場所\n",
    "            - epoch: int, 現在のエポック\n",
    "    \"\"\"\n",
    "    if test_ap > best_test_ap:\n",
    "        best_test_ap = test_ap\n",
    "        torch.save(model.state_dict(), pj(model_root, \"best.pth\"))\n",
    "        with open(pj(model_root, \"best_AP.txt\"), mode=\"w\") as f:\n",
    "            f.write(\"epoch = {}, test_ap = {}\".format(epoch, test_ap))\n",
    "    return best_test_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(pj(args.prc_root, \"train\")) is False:\n",
    "    os.makedirs(pj(args.prc_root, \"train\"))\n",
    "if os.path.exists(pj(args.prc_root, \"test\")) is False:\n",
    "    os.makedirs(pj(args.prc_root, \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_evaluater = Voc_Evaluater(args.train_image_root, args.train_target_root, pj(args.prc_root, \"train\"))\n",
    "test_evaluater = Voc_Evaluater(args.test_image_root, args.test_target_root, pj(args.prc_root, \"test\"))\n",
    "# set best AP\n",
    "best_test_ap = 0\n",
    "\n",
    "for epoch in range(args.max_epoch):\n",
    "    train_per_epoch(epoch, train_dataloader, opt, model, arm_loss, odm_loss, l2_loss, args.batch_size, lamda=args.lamda, visdom=args.visdom)\n",
    "    \n",
    "    # validate model\n",
    "    if epoch != 0 and epoch % args.valid_interval == 0:\n",
    "        train_eval_metrics = validate(train_evaluater, train_valid_dataloader, model, args.crop_num, num_classes=args.class_num, nms_thresh=0.5)\n",
    "        test_eval_metrics = validate(test_evaluater, test_dataloader, model, args.crop_num, num_classes=args.class_num, nms_thresh=0.5)\n",
    "        if args.model_detect_type == \"all\":\n",
    "            train_ap = train_eval_metrics[0]['AP']\n",
    "            test_ap = test_eval_metrics[0]['AP']\n",
    "            best_test_ap = save_model_and_disp_ap(test_ap, best_test_ap, model, args.model_root, epoch)\n",
    "            print(\"epoch: {}, train_ap={}, test_ap={}\".format(epoch, train_ap, test_ap))\n",
    "            if args.visdom:\n",
    "                visualize(vis, epoch+1, train_ap, win_train_acc)\n",
    "                visualize(vis, epoch+1, test_ap, win_test_acc)\n",
    "        elif args.model_detect_type == \"det2cls\":\n",
    "            train_aquatic_ap = train_eval_metrics[0]['AP']\n",
    "            train_other_ap = train_eval_metrics[1]['AP']\n",
    "            test_aquatic_ap = test_eval_metrics[0]['AP']\n",
    "            test_other_ap = test_eval_metrics[1]['AP']\n",
    "            train_map = (train_aquatic_ap + train_other_ap) / 2\n",
    "            test_map = (test_aquatic_ap + test_other_ap) / 2\n",
    "            best_test_ap = save_model_and_disp_ap(test_aquatic_ap, best_test_ap, model, args.model_root, epoch)\n",
    "            print(\"epoch: {}\".format(epoch))\n",
    "            print(\"train: aquatic_ap={}, other_ap={}\".format(train_aquatic_ap, train_other_ap))\n",
    "            print(\"test: aquatic_ap={}, other_ap={}\".format(test_aquatic_ap, test_other_ap))\n",
    "            print(\"mean_train_ap={}, mean_test_ap={}\".format(train_map, test_map))\n",
    "            if args.visdom:\n",
    "                visualize(vis, epoch+1, train_aquatic_ap, win_train_aquatic_acc)\n",
    "                visualize(vis, epoch+1, train_other_ap, win_train_other_acc)\n",
    "                visualize(vis, epoch+1, test_aquatic_ap, win_test_aquatic_acc)\n",
    "                visualize(vis, epoch+1, test_other_ap, win_test_other_acc)\n",
    "    \n",
    "    # save model\n",
    "    if epoch != 0 and epoch % args.save_interval == 0:\n",
    "        print('Saving state, epoch: ' + str(epoch))\n",
    "        torch.save(model.state_dict(), pj(args.model_root, \"epoch{}.pth\".format(epoch)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_100",
   "language": "python",
   "name": "pytorch_100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
