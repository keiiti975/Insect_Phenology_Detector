{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir as ld\n",
    "from os.path import join as pj\n",
    "import numpy as np\n",
    "from numpy.random import *\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from tqdm import tqdm\n",
    "import visdom\n",
    "\n",
    "# Logger\n",
    "from IO.logger import Logger\n",
    "# Loader\n",
    "from IO.loader import load_path, load_images, load_annotations_path, load_annotations, get_anno_recs\n",
    "# Dataset\n",
    "from dataset.detection.dataset import insects_dataset_from_voc_style_txt, collate_fn\n",
    "# model\n",
    "from model.faster_rcnn.faster_rcnn import make_Faster_RCNN\n",
    "# Predict\n",
    "from model.faster_rcnn.predict import test_prediction\n",
    "# Evaluate\n",
    "from evaluation.detection.evaluate import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    # experiment name\n",
    "    experiment_name = \"crop_b2_2_4_8_16_32_aaaaa\"\n",
    "    # paths\n",
    "    data_root = \"/home/tanida/workspace/Insect_Phenology_Detector/data\"\n",
    "    train_image_root = \"/home/tanida/workspace/Insect_Phenology_Detector/data/train_refined_images\"\n",
    "    train_target_root = \"/home/tanida/workspace/Insect_Phenology_Detector/data/train_detection_data/refinedet_all\"\n",
    "    test_image_root = \"/home/tanida/workspace/Insect_Phenology_Detector/data/test_refined_images\"\n",
    "    model_root = pj(\"/home/tanida/workspace/Insect_Phenology_Detector/output_model/detection/Faster_RCNN\", experiment_name)\n",
    "    test_anno_folders = [\"annotations_4\"]\n",
    "    # train config\n",
    "    b_bone = \"vgg16\"\n",
    "    anchor_size = ((2, 4, 8, 16, 32),)\n",
    "    aspect_ratio = ((0.5, 1.0, 2.0),)\n",
    "    input_size = 512 # choices=[320, 512, 1024]\n",
    "    crop_num = (5, 5)\n",
    "    lr = 1e-4\n",
    "    lamda = 1e-2\n",
    "    batch_size = 2\n",
    "    num_workers = 2\n",
    "    max_epoch = 100\n",
    "    valid_interval = 2\n",
    "    save_interval = 20\n",
    "    max_insect_per_image = 20\n",
    "    pretrain = True\n",
    "    # visualization\n",
    "    visdom = True\n",
    "    port = 8097\n",
    "    # class label\n",
    "    labels = ['__background__','insects']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.visdom:\n",
    "    # Create visdom\n",
    "    vis = visdom.Visdom(port=args.port)\n",
    "    \n",
    "    \"\"\"train_loss\"\"\"\n",
    "    win_cls_loss = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='cls_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    win_cls_box_loss = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='cls_box_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    win_obj_loss = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='obj_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    win_rpn_box_loss = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='rpn_box_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    win_total_norm_loss = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='norm_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    win_train_loss = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='train_loss',\n",
    "            xlabel='epoch',\n",
    "            ylabel='loss',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )\n",
    "    \"\"\"validation_accuracy\"\"\"\n",
    "    win_valid_acc = vis.line(\n",
    "        X=np.array([0]),\n",
    "        Y=np.array([0]),\n",
    "        opts=dict(\n",
    "            title='validation_accuracy',\n",
    "            xlabel='epoch',\n",
    "            ylabel='average precision',\n",
    "            width=800,\n",
    "            height=400\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(phase, visualized_data, window):\n",
    "    vis.line(\n",
    "        X=np.array([phase]),\n",
    "        Y=np.array([visualized_data]),\n",
    "        update='append',\n",
    "        win=window\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_loss = nn.MSELoss(reduction='mean').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_per_epoch(model, data_loader, optimizer, epoch):\n",
    "    # set Faster_RCNN to train mode\n",
    "    cls_loss = 0\n",
    "    cls_box_loss = 0\n",
    "    obj_loss = 0\n",
    "    rpn_box_loss = 0\n",
    "    total_norm_loss = 0\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    # train\n",
    "    for images, targets, _, _, _ in tqdm(data_loader, leave=False):\n",
    "        imgs = np.asarray(images[0])\n",
    "        tars = np.asarray(targets[0])\n",
    "        refined_imgs = []\n",
    "        refined_tars = []\n",
    "        # refine imgs, tars\n",
    "        for i in range(imgs.shape[0]):\n",
    "            if len(tars[i][\"boxes\"]) > 0:\n",
    "                refined_imgs.append(imgs[i])\n",
    "                refined_tars.append(tars[i])\n",
    "        imgs = np.asarray(refined_imgs)\n",
    "        tars = np.asarray(refined_tars)\n",
    "        \n",
    "        # define batch_num\n",
    "        if (imgs.shape[0]%args.batch_size == 0):\n",
    "            batch_num = int(imgs.shape[0]/args.batch_size)\n",
    "        else:\n",
    "            batch_num = int(imgs.shape[0]/args.batch_size) + 1\n",
    "        \n",
    "        # random sample of batch\n",
    "        iter_batch = choice(range(batch_num), batch_num, replace=False)\n",
    "        \n",
    "        # train for cropped image\n",
    "        for i in iter_batch:\n",
    "            images = imgs[i*args.batch_size:(i+1)*args.batch_size]\n",
    "            targets = tars[i*args.batch_size:(i+1)*args.batch_size]\n",
    "            \n",
    "            # set cuda\n",
    "            images = [torch.from_numpy(im).cuda() for im in images]\n",
    "            targets = [{k: v.cuda() for k,v in t.items()} for t in targets]\n",
    "            \n",
    "            # forward\n",
    "            optimizer.zero_grad()\n",
    "            loss_dict = model(images, targets)\n",
    "            \n",
    "            # sum loss\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            \n",
    "            # l2 normalization for model parameters\n",
    "            if args.lamda != 0:\n",
    "                norm_loss = 0\n",
    "                for param in model.parameters():\n",
    "                    param_target = torch.zeros(param.size()).cuda()\n",
    "                    norm_loss += l2_loss(param, param_target)\n",
    "                norm_loss = norm_loss * args.lamda\n",
    "                losses += norm_loss\n",
    "                total_norm_loss += norm_loss.item()\n",
    "            else:\n",
    "                norm_loss = 0\n",
    "            \n",
    "            # backward\n",
    "            if torch.isnan(losses) == 0:\n",
    "                losses.backward()\n",
    "                optimizer.step()\n",
    "                cls_loss += loss_dict['loss_classifier'].item()\n",
    "                cls_box_loss += loss_dict['loss_box_reg'].item()\n",
    "                obj_loss += loss_dict['loss_objectness'].item()\n",
    "                rpn_box_loss += loss_dict['loss_rpn_box_reg'].item()\n",
    "                total_loss += losses.item()\n",
    "        \n",
    "    print(\"epoch: {0}, cls_l: {1}, cls_box_l: {2}, obj_l: {3}, rpn_box_l: {4}, total_norm_l: {5}, total_l: {6}\".format(epoch, cls_loss, cls_box_loss, obj_loss, rpn_box_loss, total_norm_loss, total_loss))\n",
    "    # visualize\n",
    "    if args.visdom:\n",
    "        visualize(epoch + 1, cls_loss, win_cls_loss)\n",
    "        visualize(epoch + 1, cls_box_loss, win_cls_box_loss)\n",
    "        visualize(epoch + 1, obj_loss, win_obj_loss)\n",
    "        visualize(epoch + 1, rpn_box_loss, win_rpn_box_loss)\n",
    "        visualize(epoch + 1, total_norm_loss, win_total_norm_loss)\n",
    "        visualize(epoch + 1, total_loss, win_train_loss)\n",
    "\n",
    "def validate(model, data_loader, recs, input_size, crop_num, nms_thresh=0.3):\n",
    "    # set Faster_RCNN to eval mode\n",
    "    model.eval()\n",
    "    # predict and evaluate\n",
    "    result = test_prediction(model, data_loader, input_size, crop_num, nms_thresh=nms_thresh)\n",
    "    recall, precision, avg_precision, gt_dict = evaluate(result, recs, ovthresh=0.3)\n",
    "    \n",
    "    return avg_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_logger = Logger(args)\n",
    "args_logger.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading dataset for train ...')\n",
    "train_dataset = insects_dataset_from_voc_style_txt(args.train_image_root, args.input_size, args.crop_num, \"Faster_RCNN\", training=True, target_root=args.train_target_root)\n",
    "train_data_loader = data.DataLoader(train_dataset, 1, num_workers=1, shuffle=True, collate_fn=collate_fn)\n",
    "print('Loading dataset for test ...')\n",
    "test_dataset = insects_dataset_from_voc_style_txt(args.test_image_root, args.input_size, args.crop_num, \"Faster_RCNN\", training=False)\n",
    "test_data_loader = data.DataLoader(test_dataset, 1, num_workers=1, shuffle=False, collate_fn=collate_fn)\n",
    "print('Loading annotation for test...')\n",
    "test_annos, test_imgs = load_path(args.data_root, \"refined_images\", args.test_anno_folders)\n",
    "test_images = load_images(test_imgs)\n",
    "test_annotations_path = load_annotations_path(test_annos, test_images)\n",
    "test_anno = load_annotations(test_annotations_path)\n",
    "test_imagenames, test_recs = get_anno_recs(test_anno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_Faster_RCNN(len(args.labels), args.input_size, args.anchor_size, args.aspect_ratio, args.b_bone, max_insect_per_image=args.max_insect_per_image, pretrain=args.pretrain).cuda()\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(args.max_epoch):\n",
    "    train_per_epoch(model, train_data_loader, optimizer, epoch)\n",
    "    \n",
    "    # validate model\n",
    "    if epoch != 0 and epoch % args.valid_interval == 0:\n",
    "        average_precision = validate(model, test_data_loader, test_recs, args.input_size, args.crop_num)\n",
    "        print(\"epoch: {}, ap={}\".format(epoch, average_precision))\n",
    "        if args.visdom:\n",
    "            visualize(epoch+1, average_precision, win_valid_acc)\n",
    "            \n",
    "    # save model\n",
    "    if epoch != 0 and epoch % args.save_interval == 0:\n",
    "        print('Saving state, epoch: ' + str(epoch))\n",
    "        torch.save(model.state_dict(), args.model_root + '/Faster_RCNN{}_{}.pth'.format(args.input_size, str(epoch)))\n",
    "    \n",
    "print('Saving state, final')\n",
    "torch.save(model.state_dict(), args.model_root + '/Faster_RCNN{}_final.pth'.format(args.input_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_100",
   "language": "python",
   "name": "pytorch_100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
