{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir as ld\n",
    "from os.path import join as pj\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.utils.config import cfg, cfg_from_file, cfg_from_list\n",
    "from model.rpn.bbox_transform import bbox_transform_inv\n",
    "from model.rpn.bbox_transform import clip_boxes\n",
    "from model.utils.net_utils import weights_normal_init, save_net, load_net, \\\n",
    "      adjust_learning_rate, save_checkpoint, clip_gradient, vis_detections\n",
    "\n",
    "# Loader\n",
    "from IO.dataset import load_path, load_images, load_images_path, load_annotations_path, load_annotations, get_all_anno_recs\n",
    "# Dataset\n",
    "from dataset.dataset import insects_dataset_from_voc_style_txt, collate_fn\n",
    "# Predict\n",
    "from evaluation.predict import test_prediction\n",
    "# Evaluate\n",
    "from evaluation.evaluate import evaluate\n",
    "# Statistics\n",
    "from evaluation.statistics import plot_df_distrib_size, compute_size_df, plot_df_distrib_class, plot_df_error, plot_pr_curve\n",
    "# Visualize\n",
    "from evaluation.visualize import vis_detections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    # experiment name\n",
    "    experiment_name = \"crop_b2_2_4_8_16_32_not_pretrain\"\n",
    "    # paths\n",
    "    data_root = \"/home/tanida/workspace/Insect_project/data\"\n",
    "    train_image_root = \"/home/tanida/workspace/Insect_project/data/train_refined_images\"\n",
    "    test_image_root = \"/home/tanida/workspace/Insect_project/data/test_refined_images\"\n",
    "    train_target_root = \"/home/tanida/workspace/Insect_project/data/train_detection_data/refinedet_all\"\n",
    "    test_target_root = \"/home/tanida/workspace/Insect_project/data/test_detection_data/refinedet_all\"\n",
    "    model_root = pj(\"/home/tanida/workspace/Insect_project/model/detection/Faster_RCNN\", experiment_name)\n",
    "    figure_root = pj(\"/home/tanida/workspace/Insect_project/figure/detection/Faster_RCNN\", experiment_name)\n",
    "    test_anno_folders = [\"annotations_4\"]\n",
    "    # train config\n",
    "    b_bone = \"vgg16\"\n",
    "    anchor_size = ((2, 4, 8, 16, 32),)\n",
    "    aspect_ratio = ((0.5, 1.0, 2.0),)\n",
    "    input_size = 512\n",
    "    crop_num = (5, 5)\n",
    "    batch_size = 2\n",
    "    num_worker = 2\n",
    "    lr = 1e-4\n",
    "    lamda = 1e-2\n",
    "    max_epoch = 100\n",
    "    valid_interval = 2\n",
    "    save_interval = 20\n",
    "    max_insect_per_image = 20\n",
    "    # visualization\n",
    "    visdom = True\n",
    "    port = 8097\n",
    "    # class label\n",
    "    labels = ['__background__','insects']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoMLPHead(nn.Module):\n",
    "    def __init__(self, in_channels, representation_size):\n",
    "        super(TwoMLPHead, self).__init__()\n",
    "        \n",
    "        self.fc6 = nn.Linear(in_channels, representation_size)\n",
    "        self.fc7 = nn.Linear(representation_size, representation_size)\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.drop(F.relu(self.fc6(x)))\n",
    "        x = self.drop(F.relu(self.fc7(x)))\n",
    "        return x\n",
    "\n",
    "def make_Faster_RCNN(b_bone=args.b_bone, n_class=len(args.labels), anchor_size=args.anchor_size, aspect_ratio=args.aspect_ratio):\n",
    "    if b_bone == \"vgg16\":\n",
    "        b_outchannels = 512\n",
    "        representation_channels = 4096\n",
    "        backbone = torchvision.models.vgg16(pretrained=True).features\n",
    "        backbone = nn.Sequential(*list(backbone.children())[:-1])\n",
    "        backbone.out_channels = b_outchannels\n",
    "        anchor_generator = AnchorGenerator(sizes=anchor_size, aspect_ratios=aspect_ratio)\n",
    "        roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0], output_size=7, sampling_ratio=2)\n",
    "        box_header = TwoMLPHead(b_outchannels * roi_pooler.output_size[0] ** 2, representation_channels)\n",
    "        predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(representation_channels, n_class)\n",
    "        model = FasterRCNN(backbone, min_size=args.input_size, max_size=args.input_size, rpn_anchor_generator=anchor_generator, box_roi_pool=roi_pooler\n",
    "                           , box_head=box_header, box_predictor=predictor\n",
    "                           , box_detections_per_img=args.max_insect_per_image)\n",
    "    else:\n",
    "        b_outchannels = 512\n",
    "        representation_channels = 4096\n",
    "        backbone = torchvision.models.resnet34(pretrained=True)\n",
    "        backbone = nn.Sequential(*list(backbone.children())[:-3])\n",
    "        backbone.out_channels = b_outchannels\n",
    "        anchor_generator = AnchorGenerator(sizes=anchor_size, aspect_ratios=aspect_ratio)\n",
    "        roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0], output_size=7, sampling_ratio=2)\n",
    "        box_header = TwoMLPHead(b_outchannels * roi_pooler.output_size[0] ** 2, representation_channels)\n",
    "        predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(representation_channels, n_class)\n",
    "        model = FasterRCNN(backbone, min_size=args.input_size, max_size=args.input_size, rpn_anchor_generator=anchor_generator, box_roi_pool=roi_pooler\n",
    "                           , box_head=box_header, box_predictor=predictor\n",
    "                           , box_detections_per_img=args.max_insect_per_image)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Annotations for Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annos, imgs = load_path(args.data_root, args.test_anno_folders)\n",
    "images = load_images(imgs)\n",
    "annotations_path = load_annotations_path(annos, images)\n",
    "images_path = load_images_path(imgs, annotations_path)\n",
    "anno = load_annotations(annotations_path)\n",
    "imagenames, recs = get_all_anno_recs(anno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loading model for test ...\")\n",
    "load_name = pj(args.model_root, 'Faster_RCNN{}_{}.pth'.format(args.input_size, \"40\"))\n",
    "print('Loading dataset for test ...')\n",
    "test_dataset = insects_dataset_from_voc_style_txt(args.test_image_root, training=False, target_root=args.test_target_root, resize_size=args.input_size, crop_num=args.crop_num)\n",
    "test_data_loader = data.DataLoader(test_dataset, 1, num_workers=1, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_Faster_RCNN().cuda()\n",
    "model.load_state_dict(torch.load(load_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- result analysis ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test_prediction(model, test_data_loader, args.input_size, args.crop_num, nms_thresh=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- visualize accuracy distribution of size ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, precision, avg_precision, gt_dict = evaluate(result, recs)\n",
    "plot_df_distrib_size(compute_size_df(gt_dict), args.figure_root, save=True, output_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pr_curve(precision, recall, args.figure_root, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- visualize accuracy distribution of class ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_label_dic = {\n",
    "    'Coleoptera': 0,\n",
    "    'Diptera': 1,\n",
    "    'Ephemeridae': 2,\n",
    "    'Ephemeroptera': 3,\n",
    "    'Hemiptera': 4,\n",
    "    'Lepidoptera': 5,\n",
    "    'Plecoptera': 6,\n",
    "    'Trichoptera': 7,\n",
    "    'small insect': 8,\n",
    "    'medium insect': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, precision, avg_precision, gt_dict = evaluate(result, recs)\n",
    "plot_df_distrib_class(each_label_dic, gt_dict, args.figure_root, save=True, output_csv=True, color=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- visualize error count per class ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, precision, avg_precision, gt_dict = evaluate(result, recs)\n",
    "plot_df_error(each_label_dic, gt_dict, args.figure_root, save=True, output_csv=True, color=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- compare ground truth and output ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from  PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test_prediction(model, test_data_loader, args.input_size, args.crop_num, nms_thresh=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_index = 0\n",
    "index_to_key = lambda x:imagenames[x]\n",
    "if os.path.exists(args.figure_root) is False:\n",
    "    os.makedirs(args.figure_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt   = np.asarray(list(map(lambda x:x[\"bbox\"]+[1], recs[imagenames[im_index]])))\n",
    "gazo = np.asarray(Image.open(pj(\"/home/tanida/workspace/Insect_project/data/refined_images\", imagenames[im_index]+\".png\")))\n",
    "x = vis_detections(gazo, result[index_to_key(im_index)], color_name=\"blue\")\n",
    "x = vis_detections(x, gt, color_name=\"red\")\n",
    "x = Image.fromarray(x)\n",
    "x.save(pj(args.figure_root, imagenames[im_index]+\".png\"))\n",
    "print(imagenames[im_index])\n",
    "im_index += 1\n",
    "#x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- compare different iou ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for thresh in [.3, .5]:\n",
    "    recall, precision, avg_precision, gt_dict = evaluate(result, recs, ovthresh=thresh)\n",
    "    print(\"thresh == {0}, ap == {1}\".format(thresh, avg_precision))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_100",
   "language": "python",
   "name": "pytorch_100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
