{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from os import getcwd as cwd\n",
    "from os import listdir as ld\n",
    "from os.path import join as pj\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import h5py\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IO.loader import parse_annotations, file_id\n",
    "from IO.build_ds import create_annotation, adopt_DBSCAN, load_label_dic, build_classification_ds, load_anno, create_annotation\n",
    "from IO.create_bbox2size_ds import divide_target_and_body, get_new_anno_with_size\n",
    "from evaluation.classification.statistics import compute_anno_stats, compute_average_size, compute_size_correction\n",
    "from evaluation.classification.visualize import plot_size_of_anno, plot_size_by_class_of_anno\n",
    "from utils.crop import *\n",
    "from utils.annotate import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Number of annotated pictures = 73\n",
    "Number of annotations = 650\n",
    "Number of classes = 8 + 2 (medium_insect and small_insect)\n",
    "\n",
    "Average annotation per picture = 8.9\n",
    "Average size of the annotations = (73, 61) pixels \n",
    "\n",
    "Under-represented classes: Coleoptera(4), Hemiptera(4), Diptera(36)\n",
    "medium insect  =  6\n",
    "small insect   = 103\n",
    "Other classes, approx 100 = good\n",
    "\n",
    "# 9 are more than 150 on both H and W\n",
    "# 64 are more than 150 on either H or W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/tanida/workspace/Insect_Phenology_Detector/data\"\n",
    "anno_folders = [\"annotations_0\", \"annotations_2\", \"annotations_3\", \"annotations_4\", \"annotations_20200806\"]\n",
    "annos = []\n",
    "for anno_folder in anno_folders:\n",
    "    annos_name = ld(pj(root, anno_folder))\n",
    "    annos.extend([pj(root, anno_folder, x) for x in annos_name])\n",
    "imgs  = ld(pj(root, \"refined_images\"))\n",
    "imgs  = [pj(root, \"refined_images\", x) for x in imgs if x != \".ipynb_checkpoints\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {file_id(im):np.array(Image.open(im)) for im in imgs}\n",
    "annotations = {idx: list(filter(lambda x:idx in x, annos)) for idx in images}\n",
    "annotations = {k:v for  k,v in annotations.items() if len(v)>0}\n",
    "\n",
    "anno = {}\n",
    "for k,v in annotations.items():\n",
    "    anno[k]=[]\n",
    "    for x in filter(lambda x:x.endswith(\".xml\"), v):\n",
    "        anno[k].extend(parse_annotations(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adopt DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_anno = create_annotation(images, anno, unused_labels=[']'], centering=False, percent=True)\n",
    "new_anno_not_percent = create_annotation(images, anno, unused_labels=[']'], centering=False, percent=False)\n",
    "\n",
    "label_dic = load_label_dic(new_anno, each_flag=True, plus_other=False, target_with_other=False)\n",
    "\n",
    "new_anno = adopt_DBSCAN(label_dic, new_anno, new_anno_not_percent)\n",
    "\n",
    "anno = new_anno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = build_classification_ds(anno, images, crop=crop_adjusted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save classification dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lbl_map(save_lbl):\n",
    "    new_id = np.arange(len(save_lbl))\n",
    "    lbl_map = {}\n",
    "    for i in range(len(save_lbl)):\n",
    "        lbl_map.update({save_lbl[i]:new_id[i]})\n",
    "    return lbl_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_lbl = [1, 2, 3, 6, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_map = get_lbl_map(save_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- aquatic only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = []\n",
    "Y2 = []\n",
    "for i,y in enumerate(Y):\n",
    "    if y in save_lbl:\n",
    "        X2.append(X[i,:])\n",
    "        Y2.append(lbl_map[Y[i]])\n",
    "\n",
    "X2 = np.asarray(X2)\n",
    "Y2 = np.asarray(Y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- aquatic + others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = []\n",
    "Y2 = []\n",
    "for i,y in enumerate(Y):\n",
    "    if y in save_lbl:\n",
    "        X2.append(X[i,:])\n",
    "        Y2.append(lbl_map[Y[i]])\n",
    "    else:\n",
    "        X2.append(X[i,:])\n",
    "        Y2.append(len(save_lbl))\n",
    "\n",
    "X2 = np.asarray(X2)\n",
    "Y2 = np.asarray(Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, count = np.unique(Y2, return_counts=True)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"/home/tanida/workspace/Insect_Phenology_Detector/data/all_classification_data/classify_insect_20200806\") as f:\n",
    "    f.create_dataset(\"X\", data=X2)\n",
    "    f.create_dataset(\"Y\", data=Y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create image2size dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = pj(cwd(), \"data\")\n",
    "img_folder = \"refined_images\"\n",
    "anno_folders = [\"annotations_0\", \"annotations_2\", \"annotations_3\", \"annotations_4\", \"annotations_20200806\"]\n",
    "\n",
    "unused_labels = [']', 'Coleoptera', 'Hemiptera', \n",
    "                 'Hymenoptera', 'Megaloptera', 'Unknown', \n",
    "                 'unknown', 'medium insect', 'small insect', \n",
    "                 'snail', 'spider']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, anno = load_anno(data_root, img_folder, anno_folders, return_body=True)\n",
    "new_anno = create_annotation(images, anno, unused_labels, False, False)\n",
    "new_anno_div_body = divide_target_and_body(new_anno)\n",
    "new_anno_with_size = get_new_anno_with_size(new_anno_div_body)\n",
    "\n",
    "imgs, lbls, sizes = build_classification_ds(new_anno_with_size, images, crop=crop_adjusted_std, return_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, count = np.unique(lbls, return_counts=True)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"/home/tanida/workspace/Insect_Phenology_Detector/data/all_classification_data/classify_insect_std_20200806_with_size\") as f:\n",
    "    f.create_dataset(\"X\", data=imgs)\n",
    "    f.create_dataset(\"Y\", data=lbls)\n",
    "    f.create_dataset(\"size\", data=sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_to_name = {\n",
    "    0: 'Diptera', \n",
    "    1: 'Ephemeridae', \n",
    "    2: 'Ephemeroptera', \n",
    "    3: 'Lepidoptera', \n",
    "    4: 'Plecoptera', \n",
    "    5: 'Trichoptera', \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_path = pj(cwd(), \"data/all_classification_data/classify_insect_std_20200806\")\n",
    "with h5py.File(all_data_path) as f:\n",
    "    X = f[\"X\"][:]\n",
    "    Y = f[\"Y\"][:]\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diptera_filter = Y == 0\n",
    "ephemeridae_filter = Y == 1\n",
    "ephemeroptera_filter = Y == 2\n",
    "lepidoptera_filter = Y == 3\n",
    "plecoptera_filter = Y == 4\n",
    "trichoptera_filter = Y == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insect_filter = trichoptera_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_X = X[insect_filter]\n",
    "filtered_Y = Y[insect_filter]\n",
    "filtered_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = filtered_X[idx]\n",
    "label = lbl_to_name[filtered_Y[idx]]\n",
    "plt.imshow(img)\n",
    "print(label)\n",
    "idx += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_040",
   "language": "python",
   "name": "pytorch_040"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
